{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "t00 = time()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1000) (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "X_fn = './data/X_reference.npy'\n",
    "y_fn = './data/y_reference.npy'\n",
    "X = np.load(X_fn)\n",
    "y = np.load(y_fn)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN parameters\n",
    "layers = 6\n",
    "hidden_size = 100\n",
    "block_size = 2\n",
    "hidden_sizes = [hidden_size] * layers\n",
    "num_blocks = [block_size] * layers\n",
    "input_dim = 1000\n",
    "in_channels = 64\n",
    "n_classes = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "# Set up GPU/CPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '{}'.format(0)\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet\n",
    "from datasets import spectral_dataloader\n",
    "from training import run_epoch\n",
    "from torch import optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model (from scratch)\n",
    "cnn = ResNet(hidden_sizes, num_blocks, input_dim=input_dim,\n",
    "             in_channels=in_channels, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(cnn.parameters(), lr=1e-3, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the validation split\n",
    "p_val = 0.1\n",
    "n_val = int(len(y) * p_val)  # Adjusting the validation size based on your new dataset size\n",
    "idx_tr = list(range(len(y))) \n",
    "np.random.shuffle(idx_tr)\n",
    "idx_val = idx_tr[:n_val]\n",
    "idx_tr = idx_tr[n_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up DataLoaders\n",
    "batch_size = 10\n",
    "dl_tr = spectral_dataloader(X, y, idxs=idx_tr, batch_size=batch_size, shuffle=True)\n",
    "dl_val = spectral_dataloader(X, y, idxs=idx_val, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 30  \n",
    "best_val = 0\n",
    "no_improvement = 0\n",
    "max_no_improvement = 5  # Early stopping criteria\n",
    "t0 = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch!\n",
      " Epoch 1: 0.02s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train acc: 83.66, Train loss: 0.0500\n",
      "  Val acc  : 82.35, Val loss  : 0.0748\n",
      " Epoch 2: 1757.28s\n",
      "  Train acc: 91.59, Train loss: 0.0242\n",
      "  Val acc  : 90.18, Val loss  : 0.0485\n",
      " Epoch 3: 3480.82s\n",
      "  Train acc: 92.94, Train loss: 0.0199\n",
      "  Val acc  : 89.63, Val loss  : 0.0616\n",
      " Epoch 4: 5256.64s\n",
      "  Train acc: 93.82, Train loss: 0.0171\n",
      "  Val acc  : 93.10, Val loss  : 0.0195\n",
      " Epoch 5: 7027.02s\n",
      "  Train acc: 94.49, Train loss: 0.0153\n",
      "  Val acc  : 90.63, Val loss  : 0.0342\n",
      " Epoch 6: 8968.10s\n",
      "  Train acc: 95.05, Train loss: 0.0139\n",
      "  Val acc  : 90.55, Val loss  : 0.1389\n",
      " Epoch 7: 10893.23s\n",
      "  Train acc: 95.36, Train loss: 0.0127\n",
      "  Val acc  : 91.03, Val loss  : 0.0564\n",
      " Epoch 8: 12754.06s\n",
      "  Train acc: 95.80, Train loss: 0.0115\n",
      "  Val acc  : 89.78, Val loss  : 0.1342\n",
      " Epoch 9: 14844.24s\n",
      "  Train acc: 96.07, Train loss: 0.0108\n",
      "  Val acc  : 92.15, Val loss  : 0.0298\n",
      "Early stopping after 9 epochs.\n",
      "\n",
      "Training completed in: 16778.58s\n"
     ]
    }
   ],
   "source": [
    "print('Starting training from scratch!')\n",
    "for epoch in range(epochs):\n",
    "    print(' Epoch {}: {:0.2f}s'.format(epoch + 1, time() - t0))\n",
    "    \n",
    "    # Train the model\n",
    "    acc_tr, loss_tr = run_epoch(epoch, cnn, dl_tr, cuda, training=True, optimizer=optimizer)\n",
    "    print('  Train acc: {:0.2f}, Train loss: {:0.4f}'.format(acc_tr, loss_tr))\n",
    "    \n",
    "    # Validate the model\n",
    "    acc_val, loss_val = run_epoch(epoch, cnn, dl_val, cuda, training=False, optimizer=optimizer)\n",
    "    print('  Val acc  : {:0.2f}, Val loss  : {:0.4f}'.format(acc_val, loss_val))\n",
    "    \n",
    "    # Check for early stopping\n",
    "    if acc_val > best_val or epoch == 0:\n",
    "        best_val = acc_val\n",
    "        no_improvement = 0\n",
    "        # Save the best model if desired\n",
    "        torch.save(cnn.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "    \n",
    "    if no_improvement >= max_no_improvement:\n",
    "        print('Early stopping after {} epochs.'.format(epoch + 1))\n",
    "        break\n",
    "\n",
    "print('\\nTraining completed in: {:0.2f}s'.format(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def get_predictions(model, data_loader, cuda=False):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            if cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_preds), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (encoder): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(64, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(64, 100, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 100, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 100, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 100, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 100, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(2,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 100, kernel_size=(1,), stride=(2,), bias=False)\n",
       "          (1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): ResidualBlock(\n",
       "        (conv1): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "        (bn2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (shortcut): Sequential()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=3200, out_features=30, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained weights into the model\n",
    "cnn.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "cnn.eval()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
